{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import *\n",
    "# import plotly.offline as py\n",
    "# py.init_notebook_mode(connected=True)\n",
    "# import plotly.graph_objs as go\n",
    "# import plotly.tools as tls\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from Data_Processing import *\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns',None)\n",
    "pd.set_option('max_colwidth',100)\n",
    "import shutil\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/jinnan_round1_train_20181227.csv', encoding = 'gb18030')\n",
    "test  = pd.read_csv('./Data/jinnan_round1_testB_20190121.csv', encoding = 'gb18030')\n",
    "sample_id=test['样本id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 修正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试数据修正\n",
    "train.loc[train['B14']==40, 'B14'] = train['B14'].mode()\n",
    "# train.loc[1304, 'A25'] = 70\n",
    "\n",
    "# for value in padding_list:\n",
    "#     test.loc[test[column]==value,column]=test[column].mode()\n",
    "test.loc[test['B14']==785.0, 'B14'] = 385.0\n",
    "test.loc[test['A19']==310.0, 'A19'] = 300.0\n",
    "test.loc[test['A19']==700.0, 'A19'] = 100.0\n",
    "# test.loc[test['B6']==49.0, 'B6'] = 100.0\n",
    "train.loc[1304, 'A25'] = 80\n",
    "train['A25'] = train['A25'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 异常值清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "类别占比>0.9的列:(列名, 占比)\n",
      "A1 0.9863896848137536\n",
      "A2 0.9699140401146131\n",
      "A3 0.9570200573065902\n",
      "A4 0.9570200573065902\n",
      "B2 0.9842406876790831\n"
     ]
    }
   ],
   "source": [
    "# 删除类别唯一的特征\n",
    "for df in [train, test]:\n",
    "    df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1, inplace=True)\n",
    "\n",
    "# 删除某一类别占比超过90%的列\n",
    "good_cols = list(train.columns)\n",
    "print('类别占比>0.9的列:(列名, 占比)')\n",
    "for col in train.columns:\n",
    "    rate = train[col].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if rate > 0.9:\n",
    "        good_cols.remove(col)\n",
    "        print(col,rate)\n",
    "\n",
    "# 暂时不删除，后面构造特征需要\n",
    "good_cols.append('A1')\n",
    "good_cols.append('A3')\n",
    "good_cols.append('A4')\n",
    "\n",
    "# 删除异常值\n",
    "train = train[train['收率']>0.87]\n",
    "\n",
    "train = train[good_cols]\n",
    "test['收率'] = -1\n",
    "test  = test[good_cols]\n",
    "\n",
    "# 合并数据集\n",
    "target = train['收率']\n",
    "data = pd.concat([train,test],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)\n",
    "\n",
    "# 异常时间处理\n",
    "def timeTranSecond(t):\n",
    "    try:\n",
    "        t,m,s=t.split(\":\")\n",
    "    except:\n",
    "        if t=='1900/1/9 7:00':\n",
    "            return 7*3600/3600\n",
    "        elif t=='1900/1/1 2:30':\n",
    "            return (2*3600+30*60)/3600\n",
    "        elif t==\"700\":\n",
    "            return (7*3600)/3600\n",
    "        elif t==-1:\n",
    "            return -1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    try:\n",
    "        tm = (int(t)*3600+int(m)*60+int(s))/3600\n",
    "    except:\n",
    "        return (30*60)/3600\n",
    "    return tm\n",
    "\n",
    "\n",
    "for f in ['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7']:\n",
    "    try:\n",
    "        data[f] = data[f].apply(timeTranSecond)\n",
    "    except:\n",
    "        print(f,'应该在前面被删除了！')\n",
    "\n",
    "        \n",
    "def getDuration(se):\n",
    "    try:\n",
    "        sh,sm,eh,em=re.findall(r\"\\d+\\.?\\d*\",se)\n",
    "    except:\n",
    "        if se == -1:\n",
    "            return -1 \n",
    "        \n",
    "    try:\n",
    "        if int(sh)>int(eh):\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600 + 24\n",
    "        else:\n",
    "            tm = (int(eh)*3600+int(em)*60-int(sm)*60-int(sh)*3600)/3600\n",
    "    except:\n",
    "        if se=='19:-20:05':\n",
    "            return 1\n",
    "        elif se=='15:00-1600':\n",
    "            return 1\n",
    "    return tm\n",
    "\n",
    "\n",
    "for f in ['A20','A28','B4','B9','B10','B11']:\n",
    "    data[f] = data.apply(lambda df: getDuration(df[f]), axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特征定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始特征\n",
    "orig_fea_B = ['B1', 'B5','B6','B7', 'B8', 'B12', 'B14', 'A19']\n",
    "encoder_fea = []\n",
    "b14_fea = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id＋比例＋温度＋时间    注意归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_min_scaler = lambda x : (x-np.min(x))/(np.max(x)-np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取样本id值特征\n",
    "data['样本id'] = data['样本id'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "# 原料比例特征\n",
    "data['b12/b14'] = data['B12']/data['B14']\n",
    "data['a19_rate0'] = data['A19']/(data['A1']+data['A3']+data['A4']+data['B14']+data['B1']+data['B12'])\n",
    "data['b1_rate0'] = data['B1']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B14']+data['B12'])\n",
    "data['b12_rate0'] = data['B12']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B1']+data['B14'])\n",
    "data['b14_rate0'] = data['B14']/(data['A1']+data['A3']+data['A4']+data['A19']+data['B1']+data['B12'])\n",
    "\n",
    "# 温度特征，归一化\n",
    "data['A_tem_sum'] = data['A6']+data['A8']+data['A10']+data['A12']+data['A15']+data['A17']+data['A25']+data['A27']\n",
    "data['A_tem_sum'] = data[['A_tem_sum']].apply(max_min_scaler)\n",
    "\n",
    "# time，归一化\n",
    "data['A_B_time_sum'] = data['A5']+data['A7']+data['A9']+data['A11']+data['A14']+data['A16']+data['A24']+data['A26']+data['B5']+data['B7']\n",
    "data['A_B_time_sum'] = data[['A_B_time_sum']].apply(max_min_scaler)\n",
    "\n",
    "numerical_columns = ['b12/b14', 'b14_rate0', 'a19_rate0', 'b1_rate0','b12_rate0', 'A_tem_sum','A_B_time_sum']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B14 Click through rate+组合特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 强特B14的分组特征：对B14分组，求收率的max, min, mean\n",
    "df0 = data.groupby(['B14'], as_index=False)['收率'].agg({  'gb_B14_tar'+ '_mean': 'mean', \n",
    "                                                          'gb_B14_tar'+ '_max': 'max', \n",
    "                                                          'gb_B14_tar' + '_min': 'min'})\n",
    "data = pd.merge(data, df0, how='left', on=['B14'])\n",
    "\n",
    "b14_fea.append('gb_B14_tar_mean')\n",
    "b14_fea.append('gb_B14_tar_max')\n",
    "b14_fea.append('gb_B14_tar_min')\n",
    "\n",
    "# 与B14交叉特征\n",
    "for feat in orig_fea_B+['样本id']:  \n",
    "    if feat != 'B14':\n",
    "        col_name = feat + '/B14'\n",
    "        encoder_fea.append(col_name)\n",
    "        data[col_name] = data[feat]/data['B14']\n",
    "        data[col_name] =  data[[col_name]].apply(max_min_scaler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label encoder\n",
    "for f in orig_fea_B+encoder_fea:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train.shape[0]]\n",
    "test  = data[train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 鱼老开源特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['target'] = target\n",
    "train['intTarget'] = pd.cut(train['target'], 5, labels=False)\n",
    "train = pd.get_dummies(train, columns=['intTarget'])\n",
    "li = ['intTarget_0.0','intTarget_1.0','intTarget_2.0','intTarget_3.0','intTarget_4.0']\n",
    "mean_columns = []\n",
    "for f1 in orig_fea_B:\n",
    "    cate_rate = train[f1].value_counts(normalize=True, dropna=False).values[0]\n",
    "    if cate_rate < 0.90:\n",
    "        for f2 in li:\n",
    "            col_name = 'B14_to_'+f1+\"_\"+f2+'_mean'\n",
    "            mean_columns.append(col_name)\n",
    "            order_label = train.groupby([f1])[f2].mean()\n",
    "            train[col_name] = train['B14'].map(order_label)\n",
    "            miss_rate = train[col_name].isnull().sum() * 100 / train[col_name].shape[0]\n",
    "            if miss_rate > 0:\n",
    "                train = train.drop([col_name], axis=1)\n",
    "                mean_columns.remove(col_name)\n",
    "            else:\n",
    "                test[col_name] = test['B14'].map(order_label)     \n",
    "\n",
    "train.drop(li+['target'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B14 统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio ----------------------------------------------------------------------------------------------------------------\n",
    "data_df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "df0 = data_df[orig_fea_B]\n",
    "df0['num']=1\n",
    "df_new_col = pd.DataFrame()\n",
    "    \n",
    "for j in range(len(orig_fea_B)):\n",
    "    if orig_fea_B[j] != 'B14':\n",
    "        col_name = \"r_clk_\"+orig_fea_B[j]+\"_in_\"+'B14'\n",
    "        b14_fea.append(col_name)\n",
    "        gb0= df0.groupby(['B14',orig_fea_B[j]])['num'].sum()\n",
    "        df1 = df0[['B14',orig_fea_B[j]]]\n",
    "        num = df0['B14'].map(data_df['B14'].value_counts())\n",
    "        df_new_col[col_name] = ((pd.merge(df1,gb0.reset_index(),how='left',on=['B14',orig_fea_B[j]]).sort_index()['num'].fillna(value=0)/num)*100).astype(int).values\n",
    "\n",
    "for j in range(len(orig_fea_B)):\n",
    "    if orig_fea_B[j] != 'B14':\n",
    "        col_name = \"r_clk_\"+'B14'+\"_in_\"+orig_fea_B[j]\n",
    "        b14_fea.append(col_name)\n",
    "        gb0= df0.groupby([orig_fea_B[j],'B14'])['num'].sum()\n",
    "        df1 = df0[[orig_fea_B[j],'B14']]\n",
    "        num = df0[orig_fea_B[j]].map(data_df[orig_fea_B[j]].value_counts())\n",
    "        df_new_col[col_name] = ((pd.merge(df1,gb0.reset_index(),how='left',on=[orig_fea_B[j],'B14']).sort_index()['num'].fillna(value=0)/num)*100).astype(int).values\n",
    "data_df = pd.concat([data_df, df_new_col], axis=1)\n",
    "\n",
    "df0 = data_df[orig_fea_B]\n",
    "df_new_col = pd.DataFrame()\n",
    "df0['num']=1\n",
    "for i in range(len(orig_fea_B)):\n",
    "    if orig_fea_B[i] != 'B14':\n",
    "        col_name = \"num_click_of_\"+'B14'+\"_and_\"+orig_fea_B[i]\n",
    "        b14_fea.append(col_name)\n",
    "        gb0= df0.groupby([orig_fea_B[i],'B14'])['num'].sum()\n",
    "        df1 = df0[[orig_fea_B[i],'B14']]\n",
    "        gb0= (pd.merge(df1,gb0.reset_index(),how='left',\n",
    "                        on=[orig_fea_B[i],'B14']).sort_index()['num'].fillna(value=0)).astype(int)\n",
    "        df_new_col[col_name] = ((gb0-gb0.min())/(gb0.max()-gb0.min())*100).fillna(value=0).astype(int).values\n",
    "data_df = pd.concat([data_df, df_new_col], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# id进行分箱，求每个箱子的收率均值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# id对收率是正弦特点，　周期大概是５００\n",
    "data_my_df_conf = data_df.copy()\n",
    "id_splitN_fea = ['sign_num_id_16', 'sign_num_id_32']\n",
    "def get_id_splitN(x, N):\n",
    "    a = 1994/N\n",
    "    interval = []\n",
    "    for i in range(N):\n",
    "        interval.append(a*(i+1))\n",
    "    interval[-1] = 1994\n",
    "    for i in range(N):\n",
    "        if x<=interval[0]:\n",
    "            sign_num = 1\n",
    "        elif (x>interval[i]) and (x<=interval[i+1]):\n",
    "            sign_num = i+2\n",
    "\n",
    "    return sign_num\n",
    "\n",
    "data_my_df_conf['sign_num_id_16'] = data_my_df_conf.样本id.apply(lambda x: get_id_splitN(x, 16)) #把id分成１６份\n",
    "data_my_df_conf['sign_num_id_32'] = data_my_df_conf.样本id.apply(lambda x: get_id_splitN(x, 32))\n",
    "train_my_df_conf = data_my_df_conf[:train.shape[0]]\n",
    "test_my_df_conf  = data_my_df_conf[train.shape[0]:]\n",
    "\n",
    "train_my_df_conf['target'] = target.values\n",
    "\n",
    "df0 = train_my_df_conf.groupby('sign_num_id_16')['target'].mean()\n",
    "data_my_df_conf['sign_num_id_16_gb_mean'] = data_my_df_conf['sign_num_id_16'].map(df0)\n",
    "\n",
    "df0 = train_my_df_conf.groupby('sign_num_id_32')['target'].mean()\n",
    "data_my_df_conf['sign_num_id_32_gb_mean'] = data_my_df_conf['sign_num_id_32'].map(df0)\n",
    "\n",
    "del train_my_df_conf['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# onehot编码特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1381, 2445)\n",
      "(149, 2445)\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df.fillna(-1)\n",
    "\n",
    "train = data_df[:train.shape[0]]\n",
    "test = data_df[train.shape[0]:]\n",
    "\n",
    "X_train_df = train[['样本id'] + numerical_columns + mean_columns + b14_fea]       \n",
    "X_test1 = test[['样本id'] + numerical_columns +mean_columns + b14_fea]\n",
    "\n",
    "X_train = X_train_df.values\n",
    "X_test = X_test1.values\n",
    "\n",
    "# one hot\n",
    "enc = OneHotEncoder()\n",
    "for f in orig_fea_B+encoder_fea:\n",
    "    enc.fit(data[f].values.reshape(-1, 1))\n",
    "    X_train = sparse.hstack((X_train, enc.transform(train[f].values.reshape(-1, 1))), 'csr')\n",
    "    X_test = sparse.hstack((X_test, enc.transform(test[f].values.reshape(-1, 1))), 'csr')\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = target.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train['out_lines'] = train['收率'].apply(lambda x: 1 if x<=0.87 or  x>=0.999 else  0)\n",
    "# train['out_lines'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 9.18774e-05\tvalid_1's l2: 0.000106459\n",
      "[1000]\ttraining's l2: 7.4917e-05\tvalid_1's l2: 9.94349e-05\n",
      "[1500]\ttraining's l2: 6.87251e-05\tvalid_1's l2: 9.73198e-05\n",
      "Early stopping, best iteration is:\n",
      "[1744]\ttraining's l2: 6.67251e-05\tvalid_1's l2: 9.69594e-05\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.79923e-05\tvalid_1's l2: 0.00013538\n",
      "[1000]\ttraining's l2: 7.1453e-05\tvalid_1's l2: 0.000128412\n",
      "[1500]\ttraining's l2: 6.61832e-05\tvalid_1's l2: 0.000127699\n",
      "Early stopping, best iteration is:\n",
      "[1422]\ttraining's l2: 6.62264e-05\tvalid_1's l2: 0.000127688\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.66078e-05\tvalid_1's l2: 0.000139037\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's l2: 7.86834e-05\tvalid_1's l2: 0.000138386\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.83983e-05\tvalid_1's l2: 0.000130089\n",
      "Early stopping, best iteration is:\n",
      "[758]\ttraining's l2: 7.64631e-05\tvalid_1's l2: 0.000126831\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.78594e-05\tvalid_1's l2: 0.000132837\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's l2: 8.02263e-05\tvalid_1's l2: 0.000132238\n",
      "fold n°6\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.58253e-05\tvalid_1's l2: 0.000155919\n",
      "Early stopping, best iteration is:\n",
      "[596]\ttraining's l2: 7.98316e-05\tvalid_1's l2: 0.000154722\n",
      "fold n°7\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 9.20736e-05\tvalid_1's l2: 8.76551e-05\n",
      "[1000]\ttraining's l2: 7.50574e-05\tvalid_1's l2: 8.26622e-05\n",
      "Early stopping, best iteration is:\n",
      "[1396]\ttraining's l2: 6.96789e-05\tvalid_1's l2: 8.19215e-05\n",
      "fold n°8\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[500]\ttraining's l2: 8.94012e-05\tvalid_1's l2: 0.000114224\n",
      "[1000]\ttraining's l2: 7.18436e-05\tvalid_1's l2: 0.000108376\n",
      "Early stopping, best iteration is:\n",
      "[909]\ttraining's l2: 7.35455e-05\tvalid_1's l2: 0.00010822\n",
      "CV score: 0.00012088\n"
     ]
    }
   ],
   "source": [
    "param = {'num_leaves': 48,\n",
    "         'min_data_in_leaf': 10,\n",
    "         'objective': 'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "folds = KFold(n_splits=8, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=500, early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_lgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.423257\tvalid_data-rmse:0.422079\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.257176\tvalid_data-rmse:0.255865\n",
      "[200]\ttrain-rmse:0.156578\tvalid_data-rmse:0.155614\n",
      "[300]\ttrain-rmse:0.095704\tvalid_data-rmse:0.095077\n",
      "[400]\ttrain-rmse:0.058987\tvalid_data-rmse:0.058577\n",
      "[500]\ttrain-rmse:0.036892\tvalid_data-rmse:0.03689\n",
      "[600]\ttrain-rmse:0.023692\tvalid_data-rmse:0.024227\n",
      "[700]\ttrain-rmse:0.015917\tvalid_data-rmse:0.017169\n",
      "[800]\ttrain-rmse:0.011503\tvalid_data-rmse:0.013573\n",
      "[900]\ttrain-rmse:0.009149\tvalid_data-rmse:0.011927\n",
      "[1000]\ttrain-rmse:0.007907\tvalid_data-rmse:0.011194\n",
      "[1100]\ttrain-rmse:0.007218\tvalid_data-rmse:0.010855\n",
      "[1200]\ttrain-rmse:0.00675\tvalid_data-rmse:0.010667\n",
      "[1300]\ttrain-rmse:0.006393\tvalid_data-rmse:0.010555\n",
      "[1400]\ttrain-rmse:0.006073\tvalid_data-rmse:0.010447\n",
      "[1500]\ttrain-rmse:0.005766\tvalid_data-rmse:0.010374\n",
      "[1600]\ttrain-rmse:0.00551\tvalid_data-rmse:0.010325\n",
      "[1700]\ttrain-rmse:0.005248\tvalid_data-rmse:0.010278\n",
      "[1800]\ttrain-rmse:0.00507\tvalid_data-rmse:0.010247\n",
      "[1900]\ttrain-rmse:0.004872\tvalid_data-rmse:0.010204\n",
      "[2000]\ttrain-rmse:0.004648\tvalid_data-rmse:0.010171\n",
      "[2100]\ttrain-rmse:0.004478\tvalid_data-rmse:0.010155\n",
      "[2200]\ttrain-rmse:0.004339\tvalid_data-rmse:0.010143\n",
      "[2300]\ttrain-rmse:0.004187\tvalid_data-rmse:0.010122\n",
      "[2400]\ttrain-rmse:0.004047\tvalid_data-rmse:0.010105\n",
      "[2500]\ttrain-rmse:0.003926\tvalid_data-rmse:0.010096\n",
      "[2600]\ttrain-rmse:0.003812\tvalid_data-rmse:0.010083\n",
      "[2700]\ttrain-rmse:0.003698\tvalid_data-rmse:0.010069\n",
      "[2800]\ttrain-rmse:0.003592\tvalid_data-rmse:0.010069\n",
      "[2900]\ttrain-rmse:0.003494\tvalid_data-rmse:0.010067\n",
      "[3000]\ttrain-rmse:0.003393\tvalid_data-rmse:0.010062\n",
      "[3100]\ttrain-rmse:0.003303\tvalid_data-rmse:0.010057\n",
      "[3200]\ttrain-rmse:0.003208\tvalid_data-rmse:0.010054\n",
      "[3300]\ttrain-rmse:0.003113\tvalid_data-rmse:0.010053\n",
      "[3400]\ttrain-rmse:0.00303\tvalid_data-rmse:0.010048\n",
      "[3500]\ttrain-rmse:0.002948\tvalid_data-rmse:0.010048\n",
      "[3600]\ttrain-rmse:0.002874\tvalid_data-rmse:0.010047\n",
      "[3700]\ttrain-rmse:0.002789\tvalid_data-rmse:0.010043\n",
      "[3800]\ttrain-rmse:0.002706\tvalid_data-rmse:0.010039\n",
      "[3900]\ttrain-rmse:0.002637\tvalid_data-rmse:0.010035\n",
      "[4000]\ttrain-rmse:0.002572\tvalid_data-rmse:0.010031\n",
      "[4100]\ttrain-rmse:0.002501\tvalid_data-rmse:0.010029\n",
      "[4200]\ttrain-rmse:0.002442\tvalid_data-rmse:0.010032\n",
      "[4300]\ttrain-rmse:0.00238\tvalid_data-rmse:0.010028\n",
      "[4400]\ttrain-rmse:0.002316\tvalid_data-rmse:0.010028\n",
      "[4500]\ttrain-rmse:0.002261\tvalid_data-rmse:0.010025\n",
      "[4600]\ttrain-rmse:0.002211\tvalid_data-rmse:0.010026\n",
      "[4700]\ttrain-rmse:0.00215\tvalid_data-rmse:0.010026\n",
      "[4800]\ttrain-rmse:0.0021\tvalid_data-rmse:0.010026\n",
      "[4900]\ttrain-rmse:0.002046\tvalid_data-rmse:0.010022\n",
      "[5000]\ttrain-rmse:0.001995\tvalid_data-rmse:0.01002\n",
      "[5100]\ttrain-rmse:0.001946\tvalid_data-rmse:0.010019\n",
      "[5200]\ttrain-rmse:0.001892\tvalid_data-rmse:0.01002\n",
      "[5300]\ttrain-rmse:0.001854\tvalid_data-rmse:0.010019\n",
      "[5400]\ttrain-rmse:0.001809\tvalid_data-rmse:0.01002\n",
      "[5500]\ttrain-rmse:0.001768\tvalid_data-rmse:0.010019\n",
      "[5600]\ttrain-rmse:0.001733\tvalid_data-rmse:0.010021\n",
      "[5700]\ttrain-rmse:0.001696\tvalid_data-rmse:0.010021\n",
      "[5800]\ttrain-rmse:0.00166\tvalid_data-rmse:0.010019\n",
      "[5900]\ttrain-rmse:0.001621\tvalid_data-rmse:0.010018\n",
      "[6000]\ttrain-rmse:0.001588\tvalid_data-rmse:0.010018\n",
      "[6100]\ttrain-rmse:0.001551\tvalid_data-rmse:0.010018\n",
      "Stopping. Best iteration:\n",
      "[5137]\ttrain-rmse:0.001925\tvalid_data-rmse:0.010017\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.423308\tvalid_data-rmse:0.421736\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.257199\tvalid_data-rmse:0.256833\n",
      "[200]\ttrain-rmse:0.156587\tvalid_data-rmse:0.156774\n",
      "[300]\ttrain-rmse:0.095698\tvalid_data-rmse:0.096181\n",
      "[400]\ttrain-rmse:0.058982\tvalid_data-rmse:0.059722\n",
      "[500]\ttrain-rmse:0.036896\tvalid_data-rmse:0.037914\n",
      "[600]\ttrain-rmse:0.023678\tvalid_data-rmse:0.02523\n",
      "[700]\ttrain-rmse:0.015883\tvalid_data-rmse:0.018177\n",
      "[800]\ttrain-rmse:0.011424\tvalid_data-rmse:0.01454\n",
      "[900]\ttrain-rmse:0.009024\tvalid_data-rmse:0.012918\n",
      "[1000]\ttrain-rmse:0.007751\tvalid_data-rmse:0.012221\n",
      "[1100]\ttrain-rmse:0.007068\tvalid_data-rmse:0.011923\n",
      "[1200]\ttrain-rmse:0.006627\tvalid_data-rmse:0.011766\n",
      "[1300]\ttrain-rmse:0.006303\tvalid_data-rmse:0.011682\n",
      "[1400]\ttrain-rmse:0.00597\tvalid_data-rmse:0.011619\n",
      "[1500]\ttrain-rmse:0.005712\tvalid_data-rmse:0.011595\n",
      "[1600]\ttrain-rmse:0.005465\tvalid_data-rmse:0.011551\n",
      "[1700]\ttrain-rmse:0.00524\tvalid_data-rmse:0.011517\n",
      "[1800]\ttrain-rmse:0.005033\tvalid_data-rmse:0.011489\n",
      "[1900]\ttrain-rmse:0.004861\tvalid_data-rmse:0.011479\n",
      "[2000]\ttrain-rmse:0.004673\tvalid_data-rmse:0.011457\n",
      "[2100]\ttrain-rmse:0.0045\tvalid_data-rmse:0.01144\n",
      "[2200]\ttrain-rmse:0.004365\tvalid_data-rmse:0.011429\n",
      "[2300]\ttrain-rmse:0.004234\tvalid_data-rmse:0.01142\n",
      "[2400]\ttrain-rmse:0.004107\tvalid_data-rmse:0.011414\n",
      "[2500]\ttrain-rmse:0.003955\tvalid_data-rmse:0.011401\n",
      "[2600]\ttrain-rmse:0.003842\tvalid_data-rmse:0.011396\n",
      "[2700]\ttrain-rmse:0.003736\tvalid_data-rmse:0.011389\n",
      "[2800]\ttrain-rmse:0.003611\tvalid_data-rmse:0.01139\n",
      "[2900]\ttrain-rmse:0.003497\tvalid_data-rmse:0.011388\n",
      "[3000]\ttrain-rmse:0.003397\tvalid_data-rmse:0.01139\n",
      "[3100]\ttrain-rmse:0.003313\tvalid_data-rmse:0.011386\n",
      "[3200]\ttrain-rmse:0.003243\tvalid_data-rmse:0.011391\n",
      "[3300]\ttrain-rmse:0.003165\tvalid_data-rmse:0.011388\n",
      "[3400]\ttrain-rmse:0.003085\tvalid_data-rmse:0.011385\n",
      "[3500]\ttrain-rmse:0.002998\tvalid_data-rmse:0.011388\n",
      "[3600]\ttrain-rmse:0.002918\tvalid_data-rmse:0.011386\n",
      "[3700]\ttrain-rmse:0.002829\tvalid_data-rmse:0.011385\n",
      "[3800]\ttrain-rmse:0.002749\tvalid_data-rmse:0.011388\n",
      "[3900]\ttrain-rmse:0.002671\tvalid_data-rmse:0.011388\n",
      "[4000]\ttrain-rmse:0.002603\tvalid_data-rmse:0.011388\n",
      "[4100]\ttrain-rmse:0.002537\tvalid_data-rmse:0.011385\n",
      "[4200]\ttrain-rmse:0.002476\tvalid_data-rmse:0.011387\n",
      "[4300]\ttrain-rmse:0.002418\tvalid_data-rmse:0.011385\n",
      "[4400]\ttrain-rmse:0.002355\tvalid_data-rmse:0.01138\n",
      "[4500]\ttrain-rmse:0.002304\tvalid_data-rmse:0.011382\n",
      "[4600]\ttrain-rmse:0.002256\tvalid_data-rmse:0.011381\n",
      "[4700]\ttrain-rmse:0.002192\tvalid_data-rmse:0.011382\n",
      "[4800]\ttrain-rmse:0.002132\tvalid_data-rmse:0.011385\n",
      "[4900]\ttrain-rmse:0.00208\tvalid_data-rmse:0.011383\n",
      "[5000]\ttrain-rmse:0.002032\tvalid_data-rmse:0.011381\n",
      "[5100]\ttrain-rmse:0.001988\tvalid_data-rmse:0.011379\n",
      "[5200]\ttrain-rmse:0.001936\tvalid_data-rmse:0.011379\n",
      "[5300]\ttrain-rmse:0.001894\tvalid_data-rmse:0.011379\n",
      "[5400]\ttrain-rmse:0.001847\tvalid_data-rmse:0.01138\n",
      "[5500]\ttrain-rmse:0.0018\tvalid_data-rmse:0.011377\n",
      "[5600]\ttrain-rmse:0.001761\tvalid_data-rmse:0.011375\n",
      "[5700]\ttrain-rmse:0.00172\tvalid_data-rmse:0.011376\n",
      "[5800]\ttrain-rmse:0.001684\tvalid_data-rmse:0.011377\n",
      "[5900]\ttrain-rmse:0.001635\tvalid_data-rmse:0.011374\n",
      "[6000]\ttrain-rmse:0.001599\tvalid_data-rmse:0.011376\n",
      "[6100]\ttrain-rmse:0.001565\tvalid_data-rmse:0.011377\n",
      "[6200]\ttrain-rmse:0.001527\tvalid_data-rmse:0.011378\n",
      "[6300]\ttrain-rmse:0.001493\tvalid_data-rmse:0.011379\n",
      "[6400]\ttrain-rmse:0.001461\tvalid_data-rmse:0.011379\n",
      "[6500]\ttrain-rmse:0.001427\tvalid_data-rmse:0.011376\n",
      "[6600]\ttrain-rmse:0.001399\tvalid_data-rmse:0.011375\n",
      "[6700]\ttrain-rmse:0.001371\tvalid_data-rmse:0.011376\n",
      "[6800]\ttrain-rmse:0.00134\tvalid_data-rmse:0.011377\n",
      "Stopping. Best iteration:\n",
      "[5861]\ttrain-rmse:0.001652\tvalid_data-rmse:0.011374\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.423649\tvalid_data-rmse:0.419321\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.257405\tvalid_data-rmse:0.253859\n",
      "[200]\ttrain-rmse:0.156726\tvalid_data-rmse:0.153635\n",
      "[300]\ttrain-rmse:0.095782\tvalid_data-rmse:0.092937\n",
      "[400]\ttrain-rmse:0.059025\tvalid_data-rmse:0.056516\n",
      "[500]\ttrain-rmse:0.036899\tvalid_data-rmse:0.035006\n",
      "[600]\ttrain-rmse:0.023653\tvalid_data-rmse:0.022729\n",
      "[700]\ttrain-rmse:0.015832\tvalid_data-rmse:0.016257\n",
      "[800]\ttrain-rmse:0.011324\tvalid_data-rmse:0.013267\n",
      "[900]\ttrain-rmse:0.008855\tvalid_data-rmse:0.012113\n",
      "[1000]\ttrain-rmse:0.007537\tvalid_data-rmse:0.011749\n",
      "[1100]\ttrain-rmse:0.006827\tvalid_data-rmse:0.011671\n",
      "[1200]\ttrain-rmse:0.006369\tvalid_data-rmse:0.011679\n",
      "[1300]\ttrain-rmse:0.006026\tvalid_data-rmse:0.011696\n",
      "[1400]\ttrain-rmse:0.005766\tvalid_data-rmse:0.011708\n",
      "[1500]\ttrain-rmse:0.005494\tvalid_data-rmse:0.011715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600]\ttrain-rmse:0.005235\tvalid_data-rmse:0.011725\n",
      "[1700]\ttrain-rmse:0.005023\tvalid_data-rmse:0.011731\n",
      "[1800]\ttrain-rmse:0.004837\tvalid_data-rmse:0.011737\n",
      "[1900]\ttrain-rmse:0.004655\tvalid_data-rmse:0.011731\n",
      "[2000]\ttrain-rmse:0.004481\tvalid_data-rmse:0.011728\n",
      "[2100]\ttrain-rmse:0.004307\tvalid_data-rmse:0.011731\n",
      "Stopping. Best iteration:\n",
      "[1121]\ttrain-rmse:0.006706\tvalid_data-rmse:0.011667\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.422642\tvalid_data-rmse:0.42639\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.256799\tvalid_data-rmse:0.260486\n",
      "[200]\ttrain-rmse:0.156351\tvalid_data-rmse:0.159701\n",
      "[300]\ttrain-rmse:0.095563\tvalid_data-rmse:0.098563\n",
      "[400]\ttrain-rmse:0.058903\tvalid_data-rmse:0.061442\n",
      "[500]\ttrain-rmse:0.036855\tvalid_data-rmse:0.039052\n",
      "[600]\ttrain-rmse:0.02367\tvalid_data-rmse:0.025817\n",
      "[700]\ttrain-rmse:0.015885\tvalid_data-rmse:0.018395\n",
      "[800]\ttrain-rmse:0.011419\tvalid_data-rmse:0.014586\n",
      "[900]\ttrain-rmse:0.008993\tvalid_data-rmse:0.012803\n",
      "[1000]\ttrain-rmse:0.007695\tvalid_data-rmse:0.012037\n",
      "[1100]\ttrain-rmse:0.006989\tvalid_data-rmse:0.011709\n",
      "[1200]\ttrain-rmse:0.006545\tvalid_data-rmse:0.011569\n",
      "[1300]\ttrain-rmse:0.006228\tvalid_data-rmse:0.011501\n",
      "[1400]\ttrain-rmse:0.005954\tvalid_data-rmse:0.011468\n",
      "[1500]\ttrain-rmse:0.00561\tvalid_data-rmse:0.011434\n",
      "[1600]\ttrain-rmse:0.005385\tvalid_data-rmse:0.011423\n",
      "[1700]\ttrain-rmse:0.005143\tvalid_data-rmse:0.011411\n",
      "[1800]\ttrain-rmse:0.004957\tvalid_data-rmse:0.011407\n",
      "[1900]\ttrain-rmse:0.004766\tvalid_data-rmse:0.011418\n",
      "[2000]\ttrain-rmse:0.004581\tvalid_data-rmse:0.011416\n",
      "[2100]\ttrain-rmse:0.004407\tvalid_data-rmse:0.011411\n",
      "[2200]\ttrain-rmse:0.00424\tvalid_data-rmse:0.011399\n",
      "[2300]\ttrain-rmse:0.004117\tvalid_data-rmse:0.011402\n",
      "[2400]\ttrain-rmse:0.003979\tvalid_data-rmse:0.011405\n",
      "[2500]\ttrain-rmse:0.003846\tvalid_data-rmse:0.011405\n",
      "[2600]\ttrain-rmse:0.003731\tvalid_data-rmse:0.011404\n",
      "[2700]\ttrain-rmse:0.003615\tvalid_data-rmse:0.011402\n",
      "[2800]\ttrain-rmse:0.003501\tvalid_data-rmse:0.011403\n",
      "[2900]\ttrain-rmse:0.003411\tvalid_data-rmse:0.011406\n",
      "[3000]\ttrain-rmse:0.003313\tvalid_data-rmse:0.011406\n",
      "[3100]\ttrain-rmse:0.00322\tvalid_data-rmse:0.011402\n",
      "[3200]\ttrain-rmse:0.003127\tvalid_data-rmse:0.011401\n",
      "[3300]\ttrain-rmse:0.003043\tvalid_data-rmse:0.011401\n",
      "[3400]\ttrain-rmse:0.00295\tvalid_data-rmse:0.011402\n",
      "[3500]\ttrain-rmse:0.002876\tvalid_data-rmse:0.011403\n",
      "[3600]\ttrain-rmse:0.002799\tvalid_data-rmse:0.011408\n",
      "[3700]\ttrain-rmse:0.00272\tvalid_data-rmse:0.011401\n",
      "[3800]\ttrain-rmse:0.002654\tvalid_data-rmse:0.011401\n",
      "[3900]\ttrain-rmse:0.002589\tvalid_data-rmse:0.011406\n",
      "[4000]\ttrain-rmse:0.002527\tvalid_data-rmse:0.011407\n",
      "[4100]\ttrain-rmse:0.002463\tvalid_data-rmse:0.011411\n",
      "Stopping. Best iteration:\n",
      "[3128]\ttrain-rmse:0.003196\tvalid_data-rmse:0.011398\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.422834\tvalid_data-rmse:0.425046\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.256905\tvalid_data-rmse:0.258221\n",
      "[200]\ttrain-rmse:0.156427\tvalid_data-rmse:0.157073\n",
      "[300]\ttrain-rmse:0.095612\tvalid_data-rmse:0.095832\n",
      "[400]\ttrain-rmse:0.058946\tvalid_data-rmse:0.058816\n",
      "[500]\ttrain-rmse:0.036876\tvalid_data-rmse:0.036552\n",
      "[600]\ttrain-rmse:0.02366\tvalid_data-rmse:0.023505\n",
      "[700]\ttrain-rmse:0.015894\tvalid_data-rmse:0.016475\n",
      "[800]\ttrain-rmse:0.01147\tvalid_data-rmse:0.013187\n",
      "[900]\ttrain-rmse:0.009087\tvalid_data-rmse:0.012\n",
      "[1000]\ttrain-rmse:0.00784\tvalid_data-rmse:0.011695\n",
      "[1100]\ttrain-rmse:0.00715\tvalid_data-rmse:0.011655\n",
      "[1200]\ttrain-rmse:0.006668\tvalid_data-rmse:0.01169\n",
      "[1300]\ttrain-rmse:0.006289\tvalid_data-rmse:0.011749\n",
      "[1400]\ttrain-rmse:0.005977\tvalid_data-rmse:0.011771\n",
      "[1500]\ttrain-rmse:0.005726\tvalid_data-rmse:0.011814\n",
      "[1600]\ttrain-rmse:0.005488\tvalid_data-rmse:0.011841\n",
      "[1700]\ttrain-rmse:0.005255\tvalid_data-rmse:0.011862\n",
      "[1800]\ttrain-rmse:0.00505\tvalid_data-rmse:0.011863\n",
      "[1900]\ttrain-rmse:0.004885\tvalid_data-rmse:0.011863\n",
      "[2000]\ttrain-rmse:0.004722\tvalid_data-rmse:0.011865\n",
      "Stopping. Best iteration:\n",
      "[1088]\ttrain-rmse:0.007211\tvalid_data-rmse:0.01165\n",
      "\n",
      "fold n°6\n",
      "[0]\ttrain-rmse:0.423027\tvalid_data-rmse:0.423679\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.257034\tvalid_data-rmse:0.256645\n",
      "[200]\ttrain-rmse:0.156487\tvalid_data-rmse:0.15595\n",
      "[300]\ttrain-rmse:0.095654\tvalid_data-rmse:0.095076\n",
      "[400]\ttrain-rmse:0.058966\tvalid_data-rmse:0.058285\n",
      "[500]\ttrain-rmse:0.036874\tvalid_data-rmse:0.036488\n",
      "[600]\ttrain-rmse:0.023639\tvalid_data-rmse:0.023985\n",
      "[700]\ttrain-rmse:0.015811\tvalid_data-rmse:0.017386\n",
      "[800]\ttrain-rmse:0.011323\tvalid_data-rmse:0.014305\n",
      "[900]\ttrain-rmse:0.008887\tvalid_data-rmse:0.013057\n",
      "[1000]\ttrain-rmse:0.007611\tvalid_data-rmse:0.012619\n",
      "[1100]\ttrain-rmse:0.006902\tvalid_data-rmse:0.012477\n",
      "[1200]\ttrain-rmse:0.00647\tvalid_data-rmse:0.012445\n",
      "[1300]\ttrain-rmse:0.006139\tvalid_data-rmse:0.012451\n",
      "[1400]\ttrain-rmse:0.005824\tvalid_data-rmse:0.012454\n",
      "[1500]\ttrain-rmse:0.005531\tvalid_data-rmse:0.012466\n",
      "[1600]\ttrain-rmse:0.005287\tvalid_data-rmse:0.012472\n",
      "[1700]\ttrain-rmse:0.005084\tvalid_data-rmse:0.012474\n",
      "[1800]\ttrain-rmse:0.004881\tvalid_data-rmse:0.01248\n",
      "[1900]\ttrain-rmse:0.004656\tvalid_data-rmse:0.012487\n",
      "[2000]\ttrain-rmse:0.004494\tvalid_data-rmse:0.012497\n",
      "[2100]\ttrain-rmse:0.004342\tvalid_data-rmse:0.012501\n",
      "[2200]\ttrain-rmse:0.004184\tvalid_data-rmse:0.012511\n",
      "Stopping. Best iteration:\n",
      "[1205]\ttrain-rmse:0.006449\tvalid_data-rmse:0.012444\n",
      "\n",
      "fold n°7\n",
      "[0]\ttrain-rmse:0.422806\tvalid_data-rmse:0.425235\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.256901\tvalid_data-rmse:0.258969\n",
      "[200]\ttrain-rmse:0.156422\tvalid_data-rmse:0.15817\n",
      "[300]\ttrain-rmse:0.095627\tvalid_data-rmse:0.097112\n",
      "[400]\ttrain-rmse:0.058966\tvalid_data-rmse:0.060158\n",
      "[500]\ttrain-rmse:0.03692\tvalid_data-rmse:0.037843\n",
      "[600]\ttrain-rmse:0.023732\tvalid_data-rmse:0.024533\n",
      "[700]\ttrain-rmse:0.015986\tvalid_data-rmse:0.016913\n",
      "[800]\ttrain-rmse:0.011562\tvalid_data-rmse:0.012802\n",
      "[900]\ttrain-rmse:0.00918\tvalid_data-rmse:0.010822\n",
      "[1000]\ttrain-rmse:0.007931\tvalid_data-rmse:0.009914\n",
      "[1100]\ttrain-rmse:0.007216\tvalid_data-rmse:0.009508\n",
      "[1200]\ttrain-rmse:0.006752\tvalid_data-rmse:0.009311\n",
      "[1300]\ttrain-rmse:0.00637\tvalid_data-rmse:0.009212\n",
      "[1400]\ttrain-rmse:0.006065\tvalid_data-rmse:0.009152\n",
      "[1500]\ttrain-rmse:0.005805\tvalid_data-rmse:0.00911\n",
      "[1600]\ttrain-rmse:0.005593\tvalid_data-rmse:0.009092\n",
      "[1700]\ttrain-rmse:0.005372\tvalid_data-rmse:0.009063\n",
      "[1800]\ttrain-rmse:0.005179\tvalid_data-rmse:0.009053\n",
      "[1900]\ttrain-rmse:0.005\tvalid_data-rmse:0.00904\n",
      "[2000]\ttrain-rmse:0.004825\tvalid_data-rmse:0.00904\n",
      "[2100]\ttrain-rmse:0.00465\tvalid_data-rmse:0.009026\n",
      "[2200]\ttrain-rmse:0.004475\tvalid_data-rmse:0.009022\n",
      "[2300]\ttrain-rmse:0.004321\tvalid_data-rmse:0.009014\n",
      "[2400]\ttrain-rmse:0.004201\tvalid_data-rmse:0.009012\n",
      "[2500]\ttrain-rmse:0.004069\tvalid_data-rmse:0.00901\n",
      "[2600]\ttrain-rmse:0.003949\tvalid_data-rmse:0.008997\n",
      "[2700]\ttrain-rmse:0.003813\tvalid_data-rmse:0.008997\n",
      "[2800]\ttrain-rmse:0.003709\tvalid_data-rmse:0.008994\n",
      "[2900]\ttrain-rmse:0.003606\tvalid_data-rmse:0.008992\n",
      "[3000]\ttrain-rmse:0.003506\tvalid_data-rmse:0.008993\n",
      "[3100]\ttrain-rmse:0.003413\tvalid_data-rmse:0.00899\n",
      "[3200]\ttrain-rmse:0.003307\tvalid_data-rmse:0.008989\n",
      "[3300]\ttrain-rmse:0.003223\tvalid_data-rmse:0.008991\n",
      "[3400]\ttrain-rmse:0.003135\tvalid_data-rmse:0.008993\n",
      "[3500]\ttrain-rmse:0.003051\tvalid_data-rmse:0.008993\n",
      "[3600]\ttrain-rmse:0.002979\tvalid_data-rmse:0.008995\n",
      "[3700]\ttrain-rmse:0.002887\tvalid_data-rmse:0.008997\n",
      "[3800]\ttrain-rmse:0.002816\tvalid_data-rmse:0.009007\n",
      "[3900]\ttrain-rmse:0.002745\tvalid_data-rmse:0.009005\n",
      "[4000]\ttrain-rmse:0.002678\tvalid_data-rmse:0.009002\n",
      "[4100]\ttrain-rmse:0.002605\tvalid_data-rmse:0.009003\n",
      "Stopping. Best iteration:\n",
      "[3119]\ttrain-rmse:0.003387\tvalid_data-rmse:0.008987\n",
      "\n",
      "fold n°8\n",
      "[0]\ttrain-rmse:0.423362\tvalid_data-rmse:0.421349\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 1000 rounds.\n",
      "[100]\ttrain-rmse:0.257239\tvalid_data-rmse:0.255677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain-rmse:0.156601\tvalid_data-rmse:0.155275\n",
      "[300]\ttrain-rmse:0.095718\tvalid_data-rmse:0.094558\n",
      "[400]\ttrain-rmse:0.058999\tvalid_data-rmse:0.058064\n",
      "[500]\ttrain-rmse:0.036938\tvalid_data-rmse:0.036364\n",
      "[600]\ttrain-rmse:0.023719\tvalid_data-rmse:0.023711\n",
      "[700]\ttrain-rmse:0.015906\tvalid_data-rmse:0.016737\n",
      "[800]\ttrain-rmse:0.011484\tvalid_data-rmse:0.013248\n",
      "[900]\ttrain-rmse:0.009109\tvalid_data-rmse:0.01166\n",
      "[1000]\ttrain-rmse:0.007884\tvalid_data-rmse:0.010988\n",
      "[1100]\ttrain-rmse:0.007209\tvalid_data-rmse:0.01071\n",
      "[1200]\ttrain-rmse:0.006756\tvalid_data-rmse:0.010575\n",
      "[1300]\ttrain-rmse:0.006367\tvalid_data-rmse:0.010492\n",
      "[1400]\ttrain-rmse:0.00603\tvalid_data-rmse:0.010437\n",
      "[1500]\ttrain-rmse:0.005711\tvalid_data-rmse:0.010405\n",
      "[1600]\ttrain-rmse:0.005477\tvalid_data-rmse:0.010386\n",
      "[1700]\ttrain-rmse:0.005238\tvalid_data-rmse:0.010375\n",
      "[1800]\ttrain-rmse:0.005027\tvalid_data-rmse:0.01037\n",
      "[1900]\ttrain-rmse:0.004834\tvalid_data-rmse:0.010367\n",
      "[2000]\ttrain-rmse:0.004663\tvalid_data-rmse:0.010355\n",
      "[2100]\ttrain-rmse:0.004489\tvalid_data-rmse:0.010351\n",
      "[2200]\ttrain-rmse:0.004299\tvalid_data-rmse:0.010341\n",
      "[2300]\ttrain-rmse:0.004166\tvalid_data-rmse:0.010338\n",
      "[2400]\ttrain-rmse:0.004046\tvalid_data-rmse:0.010336\n",
      "[2500]\ttrain-rmse:0.003913\tvalid_data-rmse:0.010329\n",
      "[2600]\ttrain-rmse:0.003789\tvalid_data-rmse:0.010325\n",
      "[2700]\ttrain-rmse:0.003658\tvalid_data-rmse:0.010332\n",
      "[2800]\ttrain-rmse:0.003535\tvalid_data-rmse:0.010329\n",
      "[2900]\ttrain-rmse:0.003426\tvalid_data-rmse:0.010334\n",
      "[3000]\ttrain-rmse:0.003319\tvalid_data-rmse:0.010337\n",
      "[3100]\ttrain-rmse:0.003212\tvalid_data-rmse:0.01034\n",
      "[3200]\ttrain-rmse:0.00312\tvalid_data-rmse:0.010341\n",
      "[3300]\ttrain-rmse:0.003026\tvalid_data-rmse:0.010346\n",
      "[3400]\ttrain-rmse:0.002932\tvalid_data-rmse:0.010349\n",
      "[3500]\ttrain-rmse:0.002853\tvalid_data-rmse:0.010355\n",
      "Stopping. Best iteration:\n",
      "[2591]\ttrain-rmse:0.003806\tvalid_data-rmse:0.010324\n",
      "\n",
      "CV score: 0.00012173\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'eta': 0.005, \n",
    "              'max_depth': 10, \n",
    "              'subsample': 0.8, \n",
    "              'colsample_bytree': 0.8, \n",
    "              'objective': 'reg:linear', \n",
    "              'eval_metric': 'rmse', \n",
    "              'silent': True, \n",
    "              }\n",
    "\n",
    "folds = KFold(n_splits=8, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=1000, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.8f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "fold 10\n",
      "fold 11\n",
      "fold 12\n",
      "fold 13\n",
      "fold 14\n",
      "fold 15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.00011900117127429142"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将lgb和xgb的结果进行stacking\n",
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=8, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 16\n",
    "    \n",
    "mean_squared_error(target.values, oof_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df=pd.DataFrame()\n",
    "sub_df[0]=sample_id\n",
    "sub_df[1]=predictions\n",
    "sub_df[1]=sub_df[1].apply(lambda x:round(x,3))\n",
    "sub_df.to_csv(\"./submit_jinnan_10.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 高级本地存储操作，，，\n",
    "mk_new_dir = False\n",
    "if mk_new_dir==True:\n",
    "    sub_df = pd.read_csv('../jinnan_round1_submit_20181227.csv', header=None)\n",
    "    sub_df[1] = predictions\n",
    "    sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "\n",
    "    time_str = datetime.datetime.now().strftime('%m_%d_%H_%M')\n",
    "    new_dir = '../submit/{}_jinnan/'.format(time_str)\n",
    "    os.mkdir(new_dir)\n",
    "    sub_df.to_csv(new_dir+\"submit_{}.csv\".format(time_str), index=False, header=None)\n",
    "    shutil.copyfile('jinnan.ipynb', '../submit/{}_jinnan/{}.ipynb'.format(time_str, time_str))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
